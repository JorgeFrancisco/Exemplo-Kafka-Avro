# Spring Boot com Apache Kafka e Avro

Este projeto demonstra como integrar **Spring Boot** com **Apache Kafka e Avro**, focando no envio de um payload leve, e de r√°pido processamento.

---

üîπ O que √© Avro?

Apache Avro √©:

Um formato compacto, r√°pido e bin√°rio para serializar dados.

Usado para definir estruturas de dados (schemas).

Totalmente integrado com o Apache Kafka, Apache Spark, Apache Flink, Hadoop, entre outros.

Independente de linguagem: os dados Avro podem ser lidos por aplica√ß√µes escritas em Java, Python, C++, etc.

üîπ Principais Caracter√≠sticas

| Caracter√≠stica                | Descri√ß√£o                                                                     |
| ----------------------------- | ----------------------------------------------------------------------------- |
| **Schema-based**              | Usa um arquivo JSON para definir o esquema (campos, tipos, etc).              |
| **Self-describing**           | Os arquivos Avro geralmente incluem o esquema junto com os dados.             |
| **Compacto e eficiente**      | Serializa em bin√°rio, ideal para tr√°fego e armazenamento.                     |
| **Compatibilidade de vers√£o** | Permite evolu√ß√£o de schemas (adi√ß√£o/remover campos) sem quebrar consumidores. |
| **Leve**                      | N√£o exige uma estrutura pesada como XML ou JSON.                              |

üîπ Onde o Avro √© usado?

Kafka: para definir mensagens padronizadas e compactas com uso do Schema Registry.

Hadoop: como formato de armazenamento (em vez de JSON/CSV).

Data Lakes: leitura e escrita eficiente de grandes volumes de dados.

ETLs e pipelines de dados: comunica√ß√£o entre microservi√ßos.

üîπ Avro vs Outros Formatos

| Formato  | Tipo    | Vantagem                    | Desvantagem                     |
| -------- | ------- | --------------------------- | ------------------------------- |
| JSON     | Texto   | F√°cil de ler                | Muito maior em tamanho          |
| XML      | Texto   | Estruturado, mas pesado     | Verboso e lento                 |
| Protobuf | Bin√°rio | Compacto, r√°pido            | Precisa do schema externo       |
| **Avro** | Bin√°rio | Compacto, inclui o schema   | Dif√≠cil de ler manualmente      |
| Parquet  | Colunar | Ideal para leitura seletiva | Mais pesado para escrita r√°pida |

‚úÖ Quando o schema √© necess√°rio?

Em uma aplica√ß√£o Spring Boot com Kafka e Avro:

O Avro exige o schema para:

Serializar um objeto Java para bin√°rio Avro.

Desserializar bin√°rio Avro para objeto Java.

O schema pode ser:

Inclu√≠do no pr√≥prio arquivo/mensagem (self-contained).

Ou armazenado separadamente em um Schema Registry (como o do Confluent).

üìä Benchmark t√≠pico (m√©dio estimado)

| A√ß√£o                        | Avro (tempo) | Protobuf (tempo) |
| --------------------------- | ------------ | ---------------- |
| Serializar 1.000 objetos    | \~15 ms      | \~8 ms           |
| Desserializar 1.000 objetos | \~12 ms      | \~6 ms           |
| Tamanho do payload          | \~1.5x maior | menor            |

üß† Qual escolher?

| Caso de uso                              | Melhor escolha |
| ---------------------------------------- | -------------- |
| Kafka + Schema Registry                  | ‚úÖ **Avro**     |
| Microservi√ßos que exigem performance     | ‚úÖ **Protobuf** |
| Comunica√ß√£o com dispositivos IoT         | ‚úÖ **Protobuf** |
| Facilidade de schema + evolu√ß√£o din√¢mica | ‚úÖ **Avro**     |
| Integra√ß√£o com Spark, Hive, Hadoop       | ‚úÖ **Avro**     |

‚úÖ Principais vantagens do fluxo: JSON ‚Üí Avro ‚Üí Kafka

| Etapa             | Por qu√™ usar                                                 |
| ----------------- | ------------------------------------------------------------ |
| **JSON na API**   | Porque √© o formato mais comum e compat√≠vel com clientes REST |
| **Avro no Kafka** | Porque √© bin√°rio, compacto, schema-based e eficiente         |

üîç Vantagens pr√°ticas ao usar Avro no Kafka

‚úÖ 1. Redu√ß√£o de Tamanho (Payload)
JSON √© verbooso (chaves e valores em texto).

Avro √© bin√°rio e muito mais compacto (economia de at√© 50‚Äì80% no payload).

Ideal para enviar milhares de registros com menos uso de rede e disco.

‚û°Ô∏è Ganho direto em lat√™ncia e throughput do Kafka.

‚úÖ 2. Performance de Serializa√ß√£o/Desserializa√ß√£o
Avro √© muito mais r√°pido que JSON em (de)serializa√ß√£o, especialmente em grande volume.

Isso reduz o custo de CPU e melhora o desempenho dos consumidores.

‚úÖ 3. Schema Evolv√≠vel
Avro tem suporte nativo √† evolu√ß√£o de schema (adi√ß√£o, remo√ß√£o, altera√ß√£o de campos).

Kafka com Avro e Schema Registry permite manter compatibilidade entre vers√µes sem quebrar consumidores.

‚û°Ô∏è Facilita evolu√ß√£o da API e dos dados no pipeline, com menos medo de "quebrar tudo".

‚úÖ 4. Valida√ß√£o autom√°tica com Schema Registry
Se voc√™ usa Avro com o Confluent Schema Registry, os dados s√≥ s√£o aceitos no Kafka se seguirem o schema definido.

Isso previne erro de contrato entre produtor e consumidor.

‚úÖ 5. Compatibilidade multi-linguagem
Voc√™ pode produzir em Java e consumir em Python, Node, Go... sem reinventar a roda.

Basta compartilhar o schema Avro.

‚úÖ 6. Interoperabilidade com ferramentas de Big Data
Avro √© compat√≠vel com Apache Hive, Spark, Flink, Kafka Connect, Hadoop etc.

Isso permite usar os mesmos dados para analytics, batch e tempo real.

üö´ Desvantagens a considerar

| Desvantagem                           | Mitiga√ß√£o poss√≠vel                                         |
| ------------------------------------- | ---------------------------------------------------------- |
| Avro √© bin√°rio ‚Üí n√£o leg√≠vel f√°cil    | Use ferramentas como Confluent UI ou avro-tools para debug |
| Schema Registry pode ser novo p/ time | Pode come√ßar com schema embutido no in√≠cio                 |
| JSON para Avro exige mapeamento       | Use MapStruct, conversores autom√°ticos                     |

üß† Conclus√£o
Voc√™ combina o melhor dos dois mundos:

JSON: f√°cil de integrar com frontends e clientes REST.

Avro: r√°pido, compacto, seguro e preparado para evolu√ß√£o.

üìå Sim, vale muito a pena se sua API recebe grandes volumes ou voc√™ planeja escalar com Kafka, microservi√ßos ou data pipelines

üìä Benchmark: JSON vs Avro com 10.000 registros

| M√©trica                   | JSON                          | Avro                        |
| ------------------------- | ----------------------------- | --------------------------- |
| **Tamanho do payload**    | \~1.8 MB                      | \~800 KB (\~55% menor)      |
| **Tempo de serializa√ß√£o** | \~50‚Äì60 ms (com `json.dumps`) | \~20‚Äì30 ms (com `fastavro`) |
| **Formato**               | Texto leg√≠vel                 | Bin√°rio (n√£o leg√≠vel)       |
| **Valida√ß√£o de schema**   | ‚ùå N√£o                         | ‚úÖ Sim (com schema registry) |

---

## üõ†Ô∏è H√° na pasta resources o docker compose, para executar o Kafka e o RedPanda localmente. RedPanda √© uma interface gr√°fica para manipul√ßao dos t√≥picos. 
H√° tamb√©m outro arquivo, de opera√ß√µes dentro do container para manipular os t√≥picos. E mais outro arquivo para opera√ß√µes no Schema Registry

---

### Para gerar os artefatos do avsc e do mapper, etc:
mvn clean generate-resources generate-sources compile
